{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Intro-P1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S75jh18sPQH"
      },
      "source": [
        "### Data Preparation and Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P373_EoqIdY"
      },
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSkPQ5ZMscpv"
      },
      "source": [
        "train_labels = []\n",
        "train_samples = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MvWaS85teFW"
      },
      "source": [
        "Example data: \n",
        "\n",
        "- An experimental drug was tested on individuals from ages 13 to 100 in a clinical trial\n",
        "- The trial had 2100 pariticipants. Half were under 65 years old, half were 65 years or older\n",
        "- Around 95% of patients 65 or older experienced side effects\n",
        "- Around 95% of patients under 65 experienced no side effects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_sPPrttdnN"
      },
      "source": [
        "for i in range(50):\n",
        "  random_younger = randint(13, 64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1)\n",
        "\n",
        "  random_older = randint(65, 100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0)\n",
        "\n",
        "for i in range(1000):\n",
        "  random_younger = randint(13, 64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "\n",
        "  random_older = randint(65, 100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1KnSHCOu24U"
      },
      "source": [
        "train_labels = np.array(train_labels)\n",
        "train_samples = np.array(train_samples)\n",
        "train_labels, train_samples = shuffle(train_labels, train_samples)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPKF0qPPvpiW"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1, 1))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGLXuAhxv5E0",
        "outputId": "cc552d36-feaa-4160-f75f-2c15e084bf82"
      },
      "source": [
        "scaled_train_samples[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16091954],\n",
              "       [0.66666667],\n",
              "       [0.20689655],\n",
              "       [0.        ],\n",
              "       [0.08045977]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBe5KcbAwQ0N"
      },
      "source": [
        "### Simple `tf.keras` Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hwQjegUwQSF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu0_7ZzQv79V"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_shape=(1, ), activation='relu'),\n",
        "    Dense(units=32, activation='relu'),\n",
        "    Dense(units=2, activation='softmax') # Output layer\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RpjjTn4xVX3",
        "outputId": "9391db7e-4a34-421b-85d6-f46f8463fdb5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8DUueWtxXA7"
      },
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaIf_ZOH-gNU",
        "outputId": "0276cda2-be36-45bf-b493-12738eeb5363"
      },
      "source": [
        "# Training is started when call the fit function\n",
        "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "210/210 - 1s - loss: 0.7006 - accuracy: 0.4500\n",
            "Epoch 2/30\n",
            "210/210 - 0s - loss: 0.6698 - accuracy: 0.6905\n",
            "Epoch 3/30\n",
            "210/210 - 0s - loss: 0.6221 - accuracy: 0.8252\n",
            "Epoch 4/30\n",
            "210/210 - 0s - loss: 0.5792 - accuracy: 0.8481\n",
            "Epoch 5/30\n",
            "210/210 - 0s - loss: 0.5410 - accuracy: 0.8529\n",
            "Epoch 6/30\n",
            "210/210 - 0s - loss: 0.5052 - accuracy: 0.8667\n",
            "Epoch 7/30\n",
            "210/210 - 0s - loss: 0.4722 - accuracy: 0.8671\n",
            "Epoch 8/30\n",
            "210/210 - 0s - loss: 0.4425 - accuracy: 0.8795\n",
            "Epoch 9/30\n",
            "210/210 - 0s - loss: 0.4161 - accuracy: 0.8886\n",
            "Epoch 10/30\n",
            "210/210 - 0s - loss: 0.3927 - accuracy: 0.8952\n",
            "Epoch 11/30\n",
            "210/210 - 0s - loss: 0.3727 - accuracy: 0.9014\n",
            "Epoch 12/30\n",
            "210/210 - 0s - loss: 0.3551 - accuracy: 0.9110\n",
            "Epoch 13/30\n",
            "210/210 - 0s - loss: 0.3406 - accuracy: 0.9119\n",
            "Epoch 14/30\n",
            "210/210 - 0s - loss: 0.3282 - accuracy: 0.9114\n",
            "Epoch 15/30\n",
            "210/210 - 0s - loss: 0.3175 - accuracy: 0.9162\n",
            "Epoch 16/30\n",
            "210/210 - 0s - loss: 0.3083 - accuracy: 0.9138\n",
            "Epoch 17/30\n",
            "210/210 - 0s - loss: 0.3008 - accuracy: 0.9219\n",
            "Epoch 18/30\n",
            "210/210 - 0s - loss: 0.2943 - accuracy: 0.9205\n",
            "Epoch 19/30\n",
            "210/210 - 0s - loss: 0.2888 - accuracy: 0.9210\n",
            "Epoch 20/30\n",
            "210/210 - 0s - loss: 0.2841 - accuracy: 0.9243\n",
            "Epoch 21/30\n",
            "210/210 - 0s - loss: 0.2800 - accuracy: 0.9229\n",
            "Epoch 22/30\n",
            "210/210 - 0s - loss: 0.2765 - accuracy: 0.9281\n",
            "Epoch 23/30\n",
            "210/210 - 0s - loss: 0.2736 - accuracy: 0.9286\n",
            "Epoch 24/30\n",
            "210/210 - 0s - loss: 0.2710 - accuracy: 0.9281\n",
            "Epoch 25/30\n",
            "210/210 - 0s - loss: 0.2686 - accuracy: 0.9324\n",
            "Epoch 26/30\n",
            "210/210 - 0s - loss: 0.2666 - accuracy: 0.9252\n",
            "Epoch 27/30\n",
            "210/210 - 0s - loss: 0.2650 - accuracy: 0.9305\n",
            "Epoch 28/30\n",
            "210/210 - 0s - loss: 0.2633 - accuracy: 0.9343\n",
            "Epoch 29/30\n",
            "210/210 - 0s - loss: 0.2621 - accuracy: 0.9295\n",
            "Epoch 30/30\n",
            "210/210 - 0s - loss: 0.2608 - accuracy: 0.9348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f686b25f550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7joQEgpAl7p"
      },
      "source": [
        "### Creating Validation sets using Keras\n",
        "There are two ways in which we can create create validation sets while using `.fit()` function.\n",
        "- We can pass in a value for parameter `validation_data`\n",
        "- We can pass in a value for parameter `validation_split`\n",
        "\n",
        "Note: If we are using a validation set, it is important to have the data shuffled before it is passed to `fit`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aPyN2Lv-1J_",
        "outputId": "20818bca-d378-4268-eafe-77c4ea7fef52"
      },
      "source": [
        "# We create a validation set on the go\n",
        "model.fit(scaled_train_samples, train_labels, validation_split=0.1 ,batch_size=10, epochs=30, shuffle=True, verbose=2)\n",
        "# It splits out a portion of training set to the validation set\n",
        "# Here, 10% of the training data is used for the creation of a validation set"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "189/189 - 0s - loss: 0.2574 - accuracy: 0.9302 - val_loss: 0.2779 - val_accuracy: 0.9429\n",
            "Epoch 2/30\n",
            "189/189 - 0s - loss: 0.2562 - accuracy: 0.9328 - val_loss: 0.2770 - val_accuracy: 0.9429\n",
            "Epoch 3/30\n",
            "189/189 - 0s - loss: 0.2555 - accuracy: 0.9376 - val_loss: 0.2767 - val_accuracy: 0.9286\n",
            "Epoch 4/30\n",
            "189/189 - 0s - loss: 0.2544 - accuracy: 0.9317 - val_loss: 0.2759 - val_accuracy: 0.9286\n",
            "Epoch 5/30\n",
            "189/189 - 0s - loss: 0.2537 - accuracy: 0.9354 - val_loss: 0.2752 - val_accuracy: 0.9286\n",
            "Epoch 6/30\n",
            "189/189 - 0s - loss: 0.2526 - accuracy: 0.9307 - val_loss: 0.2744 - val_accuracy: 0.9429\n",
            "Epoch 7/30\n",
            "189/189 - 0s - loss: 0.2519 - accuracy: 0.9407 - val_loss: 0.2744 - val_accuracy: 0.9286\n",
            "Epoch 8/30\n",
            "189/189 - 0s - loss: 0.2513 - accuracy: 0.9302 - val_loss: 0.2735 - val_accuracy: 0.9286\n",
            "Epoch 9/30\n",
            "189/189 - 0s - loss: 0.2504 - accuracy: 0.9407 - val_loss: 0.2732 - val_accuracy: 0.9286\n",
            "Epoch 10/30\n",
            "189/189 - 0s - loss: 0.2497 - accuracy: 0.9302 - val_loss: 0.2722 - val_accuracy: 0.9286\n",
            "Epoch 11/30\n",
            "189/189 - 0s - loss: 0.2491 - accuracy: 0.9328 - val_loss: 0.2715 - val_accuracy: 0.9429\n",
            "Epoch 12/30\n",
            "189/189 - 0s - loss: 0.2485 - accuracy: 0.9392 - val_loss: 0.2709 - val_accuracy: 0.9429\n",
            "Epoch 13/30\n",
            "189/189 - 0s - loss: 0.2478 - accuracy: 0.9349 - val_loss: 0.2706 - val_accuracy: 0.9286\n",
            "Epoch 14/30\n",
            "189/189 - 0s - loss: 0.2472 - accuracy: 0.9349 - val_loss: 0.2699 - val_accuracy: 0.9429\n",
            "Epoch 15/30\n",
            "189/189 - 0s - loss: 0.2466 - accuracy: 0.9402 - val_loss: 0.2694 - val_accuracy: 0.9429\n",
            "Epoch 16/30\n",
            "189/189 - 0s - loss: 0.2460 - accuracy: 0.9392 - val_loss: 0.2691 - val_accuracy: 0.9286\n",
            "Epoch 17/30\n",
            "189/189 - 0s - loss: 0.2457 - accuracy: 0.9344 - val_loss: 0.2684 - val_accuracy: 0.9429\n",
            "Epoch 18/30\n",
            "189/189 - 0s - loss: 0.2451 - accuracy: 0.9370 - val_loss: 0.2678 - val_accuracy: 0.9429\n",
            "Epoch 19/30\n",
            "189/189 - 0s - loss: 0.2445 - accuracy: 0.9402 - val_loss: 0.2672 - val_accuracy: 0.9429\n",
            "Epoch 20/30\n",
            "189/189 - 0s - loss: 0.2441 - accuracy: 0.9349 - val_loss: 0.2667 - val_accuracy: 0.9429\n",
            "Epoch 21/30\n",
            "189/189 - 0s - loss: 0.2435 - accuracy: 0.9392 - val_loss: 0.2666 - val_accuracy: 0.9286\n",
            "Epoch 22/30\n",
            "189/189 - 0s - loss: 0.2430 - accuracy: 0.9360 - val_loss: 0.2660 - val_accuracy: 0.9429\n",
            "Epoch 23/30\n",
            "189/189 - 0s - loss: 0.2425 - accuracy: 0.9418 - val_loss: 0.2654 - val_accuracy: 0.9429\n",
            "Epoch 24/30\n",
            "189/189 - 0s - loss: 0.2421 - accuracy: 0.9381 - val_loss: 0.2652 - val_accuracy: 0.9286\n",
            "Epoch 25/30\n",
            "189/189 - 0s - loss: 0.2416 - accuracy: 0.9349 - val_loss: 0.2645 - val_accuracy: 0.9429\n",
            "Epoch 26/30\n",
            "189/189 - 0s - loss: 0.2411 - accuracy: 0.9402 - val_loss: 0.2645 - val_accuracy: 0.9286\n",
            "Epoch 27/30\n",
            "189/189 - 0s - loss: 0.2408 - accuracy: 0.9381 - val_loss: 0.2638 - val_accuracy: 0.9429\n",
            "Epoch 28/30\n",
            "189/189 - 0s - loss: 0.2403 - accuracy: 0.9418 - val_loss: 0.2633 - val_accuracy: 0.9429\n",
            "Epoch 29/30\n",
            "189/189 - 0s - loss: 0.2398 - accuracy: 0.9418 - val_loss: 0.2629 - val_accuracy: 0.9429\n",
            "Epoch 30/30\n",
            "189/189 - 0s - loss: 0.2395 - accuracy: 0.9418 - val_loss: 0.2625 - val_accuracy: 0.9429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f686a9a7610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ny6UYBxwnjk"
      },
      "source": [
        "# Creating test labels and samples\n",
        "test_labels = []\n",
        "test_samples = []\n",
        "\n",
        "for i in range(10):\n",
        "  random_younger = randint(13, 64)\n",
        "  test_samples.append(random_younger)\n",
        "  test_labels.append(1)\n",
        "\n",
        "  random_older = randint(65, 100)\n",
        "  test_samples.append(random_older)\n",
        "  test_labels.append(0)\n",
        "\n",
        "for i in range(200):\n",
        "  random_younger = randint(13, 64)\n",
        "  test_samples.append(random_younger)\n",
        "  test_labels.append(0)\n",
        "\n",
        "  random_older = randint(65, 100)\n",
        "  test_samples.append(random_older)\n",
        "  test_labels.append(1)\n",
        "\n",
        "test_labels = np.array(test_labels)\n",
        "test_samples = np.array(test_samples)\n",
        "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
        "\n",
        "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1, 1))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvx77BRLxZCi",
        "outputId": "e63bac73-4fa0-492b-ee49-4503893dcd82"
      },
      "source": [
        "# Predicting\n",
        "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)\n",
        "predictions"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.77449554, 0.22550447],\n",
              "       [0.9751863 , 0.02481373],\n",
              "       [0.9742114 , 0.02578864],\n",
              "       [0.12597282, 0.8740272 ],\n",
              "       [0.06761661, 0.9323834 ],\n",
              "       [0.97745526, 0.0225447 ],\n",
              "       [0.02154621, 0.97845376],\n",
              "       [0.5089471 , 0.4910529 ],\n",
              "       [0.9751863 , 0.02481373],\n",
              "       [0.6973081 , 0.3026919 ],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.95291287, 0.04708719],\n",
              "       [0.97619087, 0.02380921],\n",
              "       [0.09062272, 0.9093773 ],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.20392059, 0.7960794 ],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.836612  , 0.16338804],\n",
              "       [0.6973081 , 0.3026919 ],\n",
              "       [0.0783505 , 0.9216495 ],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.97737783, 0.02262214],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.977957  , 0.02204295],\n",
              "       [0.97449374, 0.02550624],\n",
              "       [0.14662401, 0.853376  ],\n",
              "       [0.12597282, 0.8740272 ],\n",
              "       [0.95826405, 0.04173591],\n",
              "       [0.9765168 , 0.02348325],\n",
              "       [0.9755256 , 0.02447438],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.02937097, 0.97062904],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.9748423 , 0.02515767],\n",
              "       [0.97619087, 0.02380921],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.20392059, 0.7960794 ],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.05012904, 0.949871  ],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.9776478 , 0.02235222],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.02328661, 0.97671336],\n",
              "       [0.95291287, 0.04708719],\n",
              "       [0.0540507 , 0.94594926],\n",
              "       [0.6071033 , 0.39289668],\n",
              "       [0.0783505 , 0.9216495 ],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.04647795, 0.953522  ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.9776478 , 0.02235222],\n",
              "       [0.97737783, 0.02262214],\n",
              "       [0.91878814, 0.08121193],\n",
              "       [0.5089471 , 0.4910529 ],\n",
              "       [0.10488416, 0.89511585],\n",
              "       [0.6535844 , 0.34641558],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.45911938, 0.5408807 ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.45911938, 0.5408807 ],\n",
              "       [0.9734196 , 0.02658042],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.02328661, 0.97671336],\n",
              "       [0.02154621, 0.97845376],\n",
              "       [0.9726792 , 0.02732087],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.97563916, 0.02436087],\n",
              "       [0.09062272, 0.9093773 ],\n",
              "       [0.95291287, 0.04708719],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.9720328 , 0.02796718],\n",
              "       [0.93889016, 0.0611099 ],\n",
              "       [0.02154621, 0.97845376],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.01993324, 0.9800668 ],\n",
              "       [0.7377279 , 0.26227212],\n",
              "       [0.9751863 , 0.02481373],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.02328661, 0.97671336],\n",
              "       [0.6535844 , 0.34641558],\n",
              "       [0.14662401, 0.853376  ],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.14662401, 0.853376  ],\n",
              "       [0.05012904, 0.949871  ],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.9749351 , 0.02506485],\n",
              "       [0.9765168 , 0.02348325],\n",
              "       [0.97737783, 0.02262214],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.9776478 , 0.02235222],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.97844785, 0.02155212],\n",
              "       [0.90311044, 0.09688962],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.96292424, 0.03707571],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.7377279 , 0.26227212],\n",
              "       [0.7377279 , 0.26227212],\n",
              "       [0.836612  , 0.16338804],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.03992141, 0.9600786 ],\n",
              "       [0.04647795, 0.953522  ],\n",
              "       [0.6973081 , 0.3026919 ],\n",
              "       [0.8074542 , 0.19254577],\n",
              "       [0.02328661, 0.97671336],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.01577219, 0.9842278 ],\n",
              "       [0.9765168 , 0.02348325],\n",
              "       [0.97682846, 0.02317157],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.09062272, 0.9093773 ],\n",
              "       [0.97449374, 0.02550624],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.836612  , 0.16338804],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.03992141, 0.9600786 ],\n",
              "       [0.97682846, 0.02317157],\n",
              "       [0.9720328 , 0.02796718],\n",
              "       [0.9667314 , 0.03326861],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.09062272, 0.9093773 ],\n",
              "       [0.9748423 , 0.02515767],\n",
              "       [0.93889016, 0.0611099 ],\n",
              "       [0.06761661, 0.9323834 ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.01843873, 0.98156124],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.9726792 , 0.02732087],\n",
              "       [0.9776478 , 0.02235222],\n",
              "       [0.9734196 , 0.02658042],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.06761661, 0.9323834 ],\n",
              "       [0.01993324, 0.9800668 ],\n",
              "       [0.02154621, 0.97845376],\n",
              "       [0.77449554, 0.22550447],\n",
              "       [0.05012904, 0.949871  ],\n",
              "       [0.23825157, 0.7617484 ],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.9758605 , 0.02413955],\n",
              "       [0.03992141, 0.9600786 ],\n",
              "       [0.12597282, 0.8740272 ],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.04647795, 0.953522  ],\n",
              "       [0.0582603 , 0.94173974],\n",
              "       [0.97737783, 0.02262214],\n",
              "       [0.9781782 , 0.02182179],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.10488416, 0.89511585],\n",
              "       [0.91878814, 0.08121193],\n",
              "       [0.04647795, 0.953522  ],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.90311044, 0.09688962],\n",
              "       [0.05012904, 0.949871  ],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.95291287, 0.04708719],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.05012904, 0.949871  ],\n",
              "       [0.96292424, 0.03707571],\n",
              "       [0.06761661, 0.9323834 ],\n",
              "       [0.0783505 , 0.9216495 ],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.5089471 , 0.4910529 ],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.93889016, 0.0611099 ],\n",
              "       [0.97563916, 0.02436087],\n",
              "       [0.01843873, 0.98156124],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.97844785, 0.02155212],\n",
              "       [0.9771047 , 0.02289524],\n",
              "       [0.9698805 , 0.03011955],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.97230136, 0.02769856],\n",
              "       [0.02937097, 0.97062904],\n",
              "       [0.77449554, 0.22550447],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.977957  , 0.02204295],\n",
              "       [0.95826405, 0.04173591],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.09062272, 0.9093773 ],\n",
              "       [0.9751863 , 0.02481373],\n",
              "       [0.8841768 , 0.11582315],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.01705433, 0.9829457 ],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.96292424, 0.03707571],\n",
              "       [0.95826405, 0.04173591],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.11374975, 0.88625026],\n",
              "       [0.9304873 , 0.06951268],\n",
              "       [0.9749351 , 0.02506485],\n",
              "       [0.8841768 , 0.11582315],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.5089471 , 0.4910529 ],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.90311044, 0.09688962],\n",
              "       [0.9771047 , 0.02289524],\n",
              "       [0.9771047 , 0.02289524],\n",
              "       [0.977957  , 0.02204295],\n",
              "       [0.9726792 , 0.02732087],\n",
              "       [0.97844785, 0.02155212],\n",
              "       [0.10488416, 0.89511585],\n",
              "       [0.9463318 , 0.05366817],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.97563916, 0.02436087],\n",
              "       [0.97230136, 0.02769856],\n",
              "       [0.97682846, 0.02317157],\n",
              "       [0.91878814, 0.08121193],\n",
              "       [0.91878814, 0.08121193],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.02328661, 0.97671336],\n",
              "       [0.9765168 , 0.02348325],\n",
              "       [0.9304873 , 0.06951268],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.06761661, 0.9323834 ],\n",
              "       [0.06761661, 0.9323834 ],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.03698482, 0.9630152 ],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.9758605 , 0.02413955],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.9720328 , 0.02796718],\n",
              "       [0.6535844 , 0.34641558],\n",
              "       [0.9755256 , 0.02447438],\n",
              "       [0.77449554, 0.22550447],\n",
              "       [0.9463318 , 0.05366817],\n",
              "       [0.97844785, 0.02155212],\n",
              "       [0.9720328 , 0.02796718],\n",
              "       [0.7377279 , 0.26227212],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.9463318 , 0.05366817],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.0540507 , 0.94594926],\n",
              "       [0.97682846, 0.02317157],\n",
              "       [0.03425656, 0.9657435 ],\n",
              "       [0.01577219, 0.9842278 ],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.01705433, 0.9829457 ],\n",
              "       [0.6071033 , 0.39289668],\n",
              "       [0.97844785, 0.02155212],\n",
              "       [0.02937097, 0.97062904],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.86210823, 0.13789171],\n",
              "       [0.9742114 , 0.02578864],\n",
              "       [0.6535844 , 0.34641558],\n",
              "       [0.0582603 , 0.94173974],\n",
              "       [0.0540507 , 0.94594926],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.91878814, 0.08121193],\n",
              "       [0.93889016, 0.0611099 ],\n",
              "       [0.9776478 , 0.02235222],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.8074542 , 0.19254577],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.03992141, 0.9600786 ],\n",
              "       [0.0783505 , 0.9216495 ],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.01705433, 0.9829457 ],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.97682846, 0.02317157],\n",
              "       [0.12597282, 0.8740272 ],\n",
              "       [0.6973081 , 0.3026919 ],\n",
              "       [0.9776478 , 0.02235222],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.9726792 , 0.02732087],\n",
              "       [0.9769424 , 0.02305759],\n",
              "       [0.0540507 , 0.94594926],\n",
              "       [0.01577219, 0.9842278 ],\n",
              "       [0.9769424 , 0.02305759],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.5089471 , 0.4910529 ],\n",
              "       [0.02937097, 0.97062904],\n",
              "       [0.02718848, 0.9728115 ],\n",
              "       [0.06277601, 0.937224  ],\n",
              "       [0.9749351 , 0.02506485],\n",
              "       [0.91878814, 0.08121193],\n",
              "       [0.97563916, 0.02436087],\n",
              "       [0.9742114 , 0.02578864],\n",
              "       [0.03992141, 0.9600786 ],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.6535844 , 0.34641558],\n",
              "       [0.6973081 , 0.3026919 ],\n",
              "       [0.9755256 , 0.02447438],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.97619087, 0.02380921],\n",
              "       [0.8074542 , 0.19254577],\n",
              "       [0.77449554, 0.22550447],\n",
              "       [0.6071033 , 0.39289668],\n",
              "       [0.20392059, 0.7960794 ],\n",
              "       [0.0783505 , 0.9216495 ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.9742114 , 0.02578864],\n",
              "       [0.95291287, 0.04708719],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.01843873, 0.98156124],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.9748423 , 0.02515767],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.9779146 , 0.02208546],\n",
              "       [0.27635622, 0.7236438 ],\n",
              "       [0.95826405, 0.04173591],\n",
              "       [0.97745526, 0.0225447 ],\n",
              "       [0.9734196 , 0.02658042],\n",
              "       [0.03172291, 0.96827716],\n",
              "       [0.9765168 , 0.02348325],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.9758605 , 0.02413955],\n",
              "       [0.9771047 , 0.02289524],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.14662401, 0.853376  ],\n",
              "       [0.08428401, 0.915716  ],\n",
              "       [0.9755256 , 0.02447438],\n",
              "       [0.9755256 , 0.02447438],\n",
              "       [0.97745526, 0.0225447 ],\n",
              "       [0.9734196 , 0.02658042],\n",
              "       [0.17341013, 0.8265898 ],\n",
              "       [0.9748423 , 0.02515767],\n",
              "       [0.0783505 , 0.9216495 ],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.9771047 , 0.02289524],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.23825157, 0.7617484 ],\n",
              "       [0.97737783, 0.02262214],\n",
              "       [0.97414047, 0.02585953],\n",
              "       [0.93889016, 0.0611099 ],\n",
              "       [0.8074542 , 0.19254577],\n",
              "       [0.02154621, 0.97845376],\n",
              "       [0.5585973 , 0.4414027 ],\n",
              "       [0.97619087, 0.02380921],\n",
              "       [0.9463318 , 0.05366817],\n",
              "       [0.04308071, 0.95691925],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.0582603 , 0.94173974],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.01843873, 0.98156124],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.9726792 , 0.02732087],\n",
              "       [0.9751863 , 0.02481373],\n",
              "       [0.9698805 , 0.03011955],\n",
              "       [0.4100961 , 0.5899039 ],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.3180109 , 0.68198913],\n",
              "       [0.9751863 , 0.02481373],\n",
              "       [0.06277601, 0.937224  ],\n",
              "       [0.06277601, 0.937224  ],\n",
              "       [0.07280146, 0.9271985 ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.9734196 , 0.02658042],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.9771047 , 0.02289524],\n",
              "       [0.23825157, 0.7617484 ],\n",
              "       [0.09743824, 0.9025618 ],\n",
              "       [0.03698482, 0.9630152 ],\n",
              "       [0.9763238 , 0.02367618],\n",
              "       [0.97449374, 0.02550624],\n",
              "       [0.02516398, 0.974836  ],\n",
              "       [0.36279616, 0.6372038 ],\n",
              "       [0.04647795, 0.953522  ],\n",
              "       [0.9737824 , 0.02621756],\n",
              "       [0.03992141, 0.9600786 ],\n",
              "       [0.0582603 , 0.94173974],\n",
              "       [0.8074542 , 0.19254577],\n",
              "       [0.9784388 , 0.02156121],\n",
              "       [0.8074542 , 0.19254577],\n",
              "       [0.90311044, 0.09688962]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIlWjE3iw83i"
      },
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhvAku6UwH5s"
      },
      "source": [
        "Using a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_IWoerrBkbP"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true=test_labels, y_pred=rounded_predictions)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORZQmOxnyBOM"
      },
      "source": [
        "def plot_confusion_metrics(cm, classes, \n",
        "                           normalize=False,\n",
        "                           title=\"COnfusion Matrix\", \n",
        "                           cmap=plt.cm.Blues):\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(classes))\n",
        "  plt.xticks(tick_marks, classes, rotation=45)\n",
        "  plt.yticks(tick_marks, classes)\n",
        "\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    print(\"Normalized Confusion Matrix\")\n",
        "\n",
        "  else:\n",
        "    print(\"Confusion Matrix, no normalization\")\n",
        "\n",
        "  print(cm)\n",
        "\n",
        "  thresh = cm.max()/2.0\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], \n",
        "             horizontalalignment=\"center\", \n",
        "             color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "UtG2oYNu0sEi",
        "outputId": "bb5a5b4c-f058-4b7d-c670-d1ed20f5e08c"
      },
      "source": [
        "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
        "plot_confusion_metrics(cm=cm, classes=cm_plot_labels, title=\"Confusion Matrix\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix, no normalization\n",
            "[[198  12]\n",
            " [ 10 200]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1PzyrQQ1B6o"
      },
      "source": [
        "### Saving and Loading a model\n",
        "\n",
        "#### 1. `model.save()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdoA0TKS0383",
        "outputId": "0ac85dc3-789f-46ef-e37d-0ae8ef9bf13e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zteFwwyl1TUY"
      },
      "source": [
        "import os.path\n",
        "if os.path.isfile(\"YOUR_PATH/filename.h5\") is False:\n",
        "   # Check if the file exists\n",
        "   model.save(\"YOUR_PATH/filename.h5\")\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92Wn1bFZ2Kg3"
      },
      "source": [
        "This functions saves:\n",
        "- The architecture of the model, allowing to re-create the model.\n",
        "- The weights of model.\n",
        "- The training configuration (loss, optimizer)\n",
        "- The state of the optimizer, allowing to resume training exactly where you left off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHWFAahq1bsv"
      },
      "source": [
        "# To upload the model\n",
        "from tensorflow.keras.models import load_model\n",
        "new_model = load_model(\"YOUR_PATH/filename.h5\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE3j4Bsi2nHJ",
        "outputId": "a6442d16-ded9-43ff-a957-7a3ec5b2ccce"
      },
      "source": [
        "new_model.summary() # To get the summary"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRRSHf7N2pw_",
        "outputId": "34c571a3-21ab-4196-8de8-13b9e3bc1ff6"
      },
      "source": [
        "new_model.get_weights() # Get the weights"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.16887549,  0.56562936, -0.31092814, -0.06263667,  0.79218084,\n",
              "          0.54503626, -0.19529083, -0.2656464 ,  0.2989006 , -0.20445746,\n",
              "         -0.15659714,  0.34985623,  0.33470348, -0.3457005 ,  0.5401763 ,\n",
              "         -0.34599695]], dtype=float32),\n",
              " array([ 0.        , -0.19353163,  0.        ,  0.        , -0.1790541 ,\n",
              "        -0.17761119,  0.        ,  0.        , -0.13120474,  0.        ,\n",
              "         0.        ,  0.21179007, -0.14233553,  0.        ,  0.08654835,\n",
              "         0.        ], dtype=float32),\n",
              " array([[ 3.48801315e-02,  9.91058648e-02,  2.88948506e-01,\n",
              "          2.26613134e-01,  3.40220064e-01,  3.70348692e-02,\n",
              "         -1.47857964e-01, -1.86778978e-01, -2.01327056e-01,\n",
              "         -8.61668587e-02,  1.66572958e-01,  2.64592618e-01,\n",
              "         -3.12931567e-01, -2.71055907e-01,  9.76985991e-02,\n",
              "         -1.07525125e-01,  3.64688337e-02, -2.07923725e-01,\n",
              "          3.36496562e-01,  1.16546154e-01, -1.54706657e-01,\n",
              "          4.77853417e-03, -1.03940949e-01,  3.09468478e-01,\n",
              "         -2.52808183e-01, -2.08722740e-01,  3.13122660e-01,\n",
              "          1.53818518e-01,  3.49001259e-01,  2.85896361e-02,\n",
              "          3.36386532e-01, -1.20364904e-01],\n",
              "        [-3.41773838e-01, -1.62500143e-01,  2.58096606e-01,\n",
              "         -3.86200249e-01, -2.91076511e-01, -6.75683022e-02,\n",
              "         -5.80564976e-01, -9.89861786e-02,  1.08067445e-01,\n",
              "         -4.25310135e-01,  3.80019069e-01, -3.15529317e-01,\n",
              "         -7.33851492e-02, -3.83737832e-01,  1.95135236e-01,\n",
              "          4.05167639e-01,  1.29496664e-01, -4.18045223e-02,\n",
              "          3.21207233e-02,  2.64161915e-01, -1.04440577e-01,\n",
              "         -5.85463047e-01,  4.27674592e-01, -3.50260496e-01,\n",
              "         -2.54540503e-01, -1.26303539e-01, -1.94641799e-01,\n",
              "          2.32918710e-01,  2.62057275e-01, -9.59311128e-02,\n",
              "         -1.21166348e-01,  5.03764510e-01],\n",
              "        [-5.08898795e-02,  7.63804615e-02, -1.51645288e-01,\n",
              "         -1.21788040e-01,  3.14524084e-01,  2.40382761e-01,\n",
              "          3.19623679e-01,  8.68293345e-02, -1.30357921e-01,\n",
              "         -2.74928361e-01,  3.11346203e-01,  3.34321290e-01,\n",
              "         -7.47176707e-02, -1.31223783e-01,  6.90730214e-02,\n",
              "         -1.29460618e-01,  1.44470930e-02,  3.65346670e-03,\n",
              "          1.72232360e-01,  5.44010401e-02, -3.25739324e-01,\n",
              "          2.84788102e-01, -2.24658206e-01,  2.63315439e-03,\n",
              "          1.76080078e-01,  2.37792581e-01, -1.20648056e-01,\n",
              "          3.04697365e-01, -2.33839720e-01, -4.81915474e-03,\n",
              "         -1.21956706e-01, -2.72578418e-01],\n",
              "        [-5.08564115e-02, -3.36430222e-01, -1.59759820e-01,\n",
              "          1.56024665e-01, -1.63696080e-01,  6.60877824e-02,\n",
              "         -2.74823755e-01, -3.20699990e-01,  2.20584720e-01,\n",
              "         -2.31044471e-01, -3.42690051e-02,  2.79565006e-01,\n",
              "          2.12243587e-01, -2.21716017e-01,  3.22385699e-01,\n",
              "          2.01763600e-01,  6.50149584e-02, -2.97281533e-01,\n",
              "          2.63207465e-01,  1.95122808e-01,  2.11973280e-01,\n",
              "         -2.30449259e-01,  2.52801865e-01,  2.05919713e-01,\n",
              "          2.50760317e-02, -1.45376951e-01,  2.02421218e-01,\n",
              "          2.64006764e-01,  1.15752220e-03,  1.64147466e-01,\n",
              "         -1.62764713e-01, -1.71414271e-01],\n",
              "        [ 1.29615441e-01, -3.77655089e-01, -1.69598922e-01,\n",
              "         -2.46822044e-01,  1.06354266e-01,  3.46628465e-02,\n",
              "         -2.31697527e-03, -1.34108663e-02,  6.11461163e-01,\n",
              "          4.33415128e-03,  3.88680339e-01, -4.55977976e-01,\n",
              "          1.55945987e-01,  7.18409717e-02,  5.33094406e-01,\n",
              "          2.46912569e-01,  5.22081614e-01, -2.56592959e-01,\n",
              "          3.95763785e-01, -5.33950925e-02, -1.57354191e-01,\n",
              "         -4.45994347e-01,  5.53646207e-01, -2.60946393e-01,\n",
              "         -1.16307080e-01,  2.80856550e-01, -4.80775893e-01,\n",
              "         -5.77330589e-04, -3.35586697e-01,  2.94756055e-01,\n",
              "          2.76428014e-01,  1.85996339e-01],\n",
              "        [ 9.09402668e-02, -5.12246847e-01, -9.98535454e-02,\n",
              "         -5.75509548e-01, -2.81885207e-01, -2.53295302e-01,\n",
              "         -1.29843861e-01,  6.78265095e-02,  6.84326649e-01,\n",
              "         -5.39679885e-01,  2.12765068e-01, -3.63501489e-01,\n",
              "         -3.23378652e-01,  1.87692031e-01,  8.34168866e-02,\n",
              "          2.63880193e-01,  4.82829899e-01, -2.33061105e-01,\n",
              "          4.97710377e-01,  7.30090439e-02, -1.71952277e-01,\n",
              "         -3.40809137e-01,  5.36301553e-01, -3.82363826e-01,\n",
              "         -1.82644144e-01,  1.39980361e-01, -6.87776553e-03,\n",
              "         -3.08511645e-01,  3.31589669e-01, -1.79296225e-01,\n",
              "         -3.03877592e-02,  4.11716968e-01],\n",
              "        [-2.67728508e-01, -2.96931863e-01, -3.45034003e-01,\n",
              "         -2.17034355e-01, -9.25762355e-02,  2.78555065e-01,\n",
              "          1.76168412e-01, -2.99388438e-01, -1.86300874e-01,\n",
              "          3.40151787e-03,  9.21124518e-02,  6.89530373e-03,\n",
              "         -1.35357082e-02, -1.25916570e-01,  1.28613800e-01,\n",
              "          4.96581197e-03,  1.11141801e-03, -1.82684496e-01,\n",
              "         -1.99050874e-01,  3.39560121e-01,  2.60010451e-01,\n",
              "          3.46975178e-01, -2.28800908e-01, -2.45692432e-02,\n",
              "          2.93480903e-01, -3.99923325e-03, -3.37182522e-01,\n",
              "         -2.92696625e-01,  2.81775385e-01,  3.23458582e-01,\n",
              "          3.46452922e-01, -2.30931684e-01],\n",
              "        [ 6.17523789e-02, -2.76174545e-01,  8.77026021e-02,\n",
              "          2.68099219e-01,  3.10862333e-01, -3.40078354e-01,\n",
              "          2.67176330e-02,  6.99230433e-02,  2.39175767e-01,\n",
              "          1.74398929e-01,  3.35876435e-01, -4.14505005e-02,\n",
              "         -8.61863494e-02, -1.39694810e-02,  1.91904992e-01,\n",
              "          1.61051124e-01, -3.51669788e-02, -1.06445819e-01,\n",
              "         -3.45407754e-01, -2.37542003e-01, -2.34370232e-02,\n",
              "         -1.41457796e-01, -1.33477449e-02, -1.96064860e-01,\n",
              "          1.52744323e-01, -9.32446718e-02,  2.96847612e-01,\n",
              "          2.45267600e-01,  1.39902085e-01, -4.45422232e-02,\n",
              "         -3.12288076e-01,  2.50869304e-01],\n",
              "        [ 8.55284929e-03, -5.39436460e-01, -9.42675769e-02,\n",
              "         -2.61004597e-01,  3.04703116e-02, -2.93276548e-01,\n",
              "         -6.05989635e-01,  1.07370913e-02,  4.24594223e-01,\n",
              "         -2.48312473e-01,  3.86459231e-01, -7.06053257e-01,\n",
              "         -3.19948018e-01,  1.07500859e-01,  2.73168832e-01,\n",
              "          7.02049315e-01,  1.30928189e-01, -3.76983285e-02,\n",
              "          4.74616319e-01,  1.52482718e-01, -5.98158181e-01,\n",
              "         -7.05700696e-01,  5.75892687e-01, -5.39757669e-01,\n",
              "         -2.40862817e-01, -1.49389192e-01, -5.90058327e-01,\n",
              "          2.88433045e-01,  3.01649123e-01,  1.56549484e-01,\n",
              "         -7.35400915e-02,  2.76603222e-01],\n",
              "        [ 1.38844520e-01, -2.69137710e-01,  1.26509070e-01,\n",
              "         -2.59031743e-01, -3.11337590e-01, -1.21579915e-01,\n",
              "          8.05459917e-02, -1.33267149e-01, -4.74853218e-02,\n",
              "         -9.94674861e-02, -1.68745533e-01, -2.11615026e-01,\n",
              "         -1.25216171e-01, -6.35958016e-02, -1.27650201e-02,\n",
              "          1.08102441e-01,  2.93721288e-01, -3.08890700e-01,\n",
              "          2.39594728e-01, -2.35252663e-01, -2.34453231e-01,\n",
              "          1.43436164e-01,  5.26951849e-02,  3.08493525e-01,\n",
              "         -6.02510273e-02, -5.02210855e-02, -1.49817035e-01,\n",
              "          1.34119779e-01, -2.90473878e-01,  3.15584391e-01,\n",
              "          1.41742617e-01,  6.22254610e-03],\n",
              "        [-1.51005834e-01,  6.69912398e-02,  2.71421582e-01,\n",
              "         -1.78030819e-01,  2.10869014e-02, -5.35056889e-02,\n",
              "         -3.21593344e-01,  6.58181310e-03,  1.18571401e-01,\n",
              "          1.32958800e-01,  1.93247765e-01,  5.59496880e-02,\n",
              "         -1.35286659e-01,  9.02886689e-02, -2.69960999e-01,\n",
              "         -1.28149942e-01, -7.99345374e-02,  8.29651952e-03,\n",
              "         -3.32575798e-01, -1.48234665e-02, -2.81967521e-02,\n",
              "         -1.14658058e-01, -2.08068445e-01, -1.61200479e-01,\n",
              "         -3.45637947e-01,  2.04125196e-01, -3.50668699e-01,\n",
              "         -2.92937368e-01, -1.06858775e-01,  1.33323967e-02,\n",
              "          1.07715964e-01,  2.42479354e-01],\n",
              "        [ 9.68784094e-04,  1.90286204e-01, -9.02551115e-02,\n",
              "          2.61262394e-02, -4.38929200e-02,  3.63761187e-03,\n",
              "          5.85694127e-02, -2.36523479e-01, -1.87990502e-01,\n",
              "          2.72204697e-01, -8.95682871e-02,  3.29187065e-01,\n",
              "          1.62267908e-01, -3.72252092e-02,  3.30139011e-01,\n",
              "         -5.03886826e-02,  7.19033033e-02, -1.46813065e-01,\n",
              "         -1.02092698e-02, -3.51296097e-01,  2.57017553e-01,\n",
              "          3.66200358e-01,  3.03635538e-01, -2.10848097e-02,\n",
              "          1.09889016e-01,  1.39370322e-01,  2.88894653e-01,\n",
              "         -5.91913760e-02, -2.56581575e-01, -8.39001238e-02,\n",
              "         -2.41931558e-01,  3.95429939e-01],\n",
              "        [-2.75876492e-01, -2.57774889e-01,  1.98278934e-01,\n",
              "         -6.02250755e-01,  3.38352531e-01, -1.50057971e-02,\n",
              "         -3.59723747e-01,  6.60739541e-02,  5.88986218e-01,\n",
              "         -5.71667254e-01,  1.03820920e-01, -4.93849427e-01,\n",
              "          1.01554722e-01, -2.15822700e-02,  2.07951784e-01,\n",
              "          2.53952891e-01,  1.15808137e-02,  1.61873728e-01,\n",
              "          6.78182662e-01,  5.22291362e-02, -1.31128787e-03,\n",
              "         -4.55947369e-01,  5.96976995e-01, -2.55342335e-01,\n",
              "         -6.46297693e-01, -1.39829129e-01, -6.14138424e-01,\n",
              "         -3.46159399e-01,  1.84741706e-01, -2.37785429e-01,\n",
              "         -2.33628988e-01,  4.79294062e-01],\n",
              "        [ 9.75857079e-02, -3.07841837e-01, -2.77585119e-01,\n",
              "          3.38379830e-01, -1.61212280e-01, -2.34512478e-01,\n",
              "         -3.15727770e-01,  9.41236913e-02, -1.42619029e-01,\n",
              "          3.17857593e-01,  1.47638291e-01, -2.64926553e-02,\n",
              "          2.28333503e-01,  7.39395618e-02, -2.59273946e-02,\n",
              "         -1.13075942e-01,  1.57121509e-01, -1.03598222e-01,\n",
              "         -1.67365074e-02,  1.40097052e-01, -1.23469189e-01,\n",
              "         -2.41578490e-01,  2.43610889e-01,  3.05118859e-02,\n",
              "         -2.05396429e-01,  3.39409143e-01, -1.97384313e-01,\n",
              "          1.30451322e-01,  1.70534551e-02, -2.93758035e-01,\n",
              "         -1.36798292e-01, -1.73597470e-01],\n",
              "        [-3.32625955e-01,  8.06964375e-03, -1.82939664e-01,\n",
              "          2.45585904e-01, -2.62968421e-01, -3.35663140e-01,\n",
              "         -7.52213076e-02, -2.24590272e-01,  1.03991613e-01,\n",
              "         -2.52899677e-01,  3.86126816e-01,  9.84270796e-02,\n",
              "         -2.12514862e-01,  8.62584561e-02,  4.79479656e-02,\n",
              "          4.53885525e-01,  2.18640059e-01,  1.15207180e-01,\n",
              "          1.39906511e-01, -8.29240978e-02,  1.22206442e-01,\n",
              "          1.80944517e-01,  3.30396354e-01,  2.05434337e-01,\n",
              "          1.80694327e-01, -3.75143230e-01, -1.15874127e-01,\n",
              "         -2.77844995e-01, -3.46348643e-01, -2.16639683e-01,\n",
              "          3.50878127e-02, -1.43275186e-01],\n",
              "        [ 1.15547687e-01, -1.83689952e-01, -6.96715117e-02,\n",
              "         -3.44181180e-01,  5.19717932e-02,  2.67552406e-01,\n",
              "          6.14559948e-02, -1.28696322e-01, -5.04243076e-02,\n",
              "         -2.01276571e-01, -2.20007554e-01, -2.47495741e-01,\n",
              "         -1.91740081e-01,  2.18639106e-01,  1.86264515e-03,\n",
              "          1.19452268e-01, -3.32626402e-02, -3.32711011e-01,\n",
              "          2.42555290e-01, -1.72124013e-01, -3.46860886e-01,\n",
              "         -2.61561394e-01,  1.15720481e-01,  3.96979451e-02,\n",
              "         -1.79378748e-01, -2.47101665e-01, -2.14071602e-01,\n",
              "         -2.78838754e-01, -1.83102429e-01, -2.85855442e-01,\n",
              "          1.73472792e-01,  3.01929623e-01]], dtype=float32),\n",
              " array([-0.00051868,  0.24447182,  0.        ,  0.22587895, -0.00051849,\n",
              "        -0.00051866,  0.22230075,  0.        , -0.07240085,  0.25290456,\n",
              "        -0.13125081,  0.21037671, -0.01677488,  0.04442778, -0.12984364,\n",
              "        -0.14422159, -0.12266591, -0.00169657, -0.10487008,  0.        ,\n",
              "         0.09791085,  0.20739155, -0.13466512,  0.21025813,  0.08960322,\n",
              "        -0.01518039,  0.23680232,  0.        ,  0.        , -0.00181133,\n",
              "        -0.00299868, -0.12859362], dtype=float32),\n",
              " array([[-3.9889881e-01, -2.5984032e-02],\n",
              "        [ 6.3717186e-01, -7.5888360e-01],\n",
              "        [ 2.8927079e-01, -3.3692494e-01],\n",
              "        [ 8.2650203e-01, -6.5757620e-01],\n",
              "        [-9.9068716e-02,  2.1027930e-02],\n",
              "        [ 5.7221364e-02,  3.5793674e-01],\n",
              "        [ 9.0120631e-01, -5.3226995e-01],\n",
              "        [ 9.2392057e-02,  3.2323524e-01],\n",
              "        [-6.6899318e-01,  6.8387426e-02],\n",
              "        [ 4.6008089e-01, -9.6614486e-01],\n",
              "        [-2.1456939e-01,  5.3969544e-01],\n",
              "        [ 7.1436924e-01, -8.8728333e-01],\n",
              "        [-3.2328269e-01, -1.4314122e-01],\n",
              "        [ 9.4330914e-02,  8.0790229e-02],\n",
              "        [-6.2793005e-01,  3.2739654e-01],\n",
              "        [-4.4419500e-01,  2.4786609e-01],\n",
              "        [-6.1539489e-01,  3.3726966e-01],\n",
              "        [ 1.8250372e-01,  3.5816869e-01],\n",
              "        [-4.4719514e-01,  4.2857903e-01],\n",
              "        [ 2.4803579e-02, -1.5003154e-01],\n",
              "        [ 4.0680474e-01, -3.6925260e-02],\n",
              "        [ 9.0355968e-01, -8.9394200e-01],\n",
              "        [ 4.8776638e-02,  6.1065865e-01],\n",
              "        [ 5.1362884e-01, -9.3516618e-01],\n",
              "        [ 4.3867791e-01, -5.2696385e-04],\n",
              "        [ 2.3106739e-01, -1.2272379e-01],\n",
              "        [ 8.9583510e-01, -4.4570604e-01],\n",
              "        [ 1.6952810e-01,  1.2549636e-01],\n",
              "        [ 5.9558481e-02, -4.1978747e-01],\n",
              "        [-3.0035937e-01, -2.7962014e-01],\n",
              "        [-2.3383673e-01,  1.6426286e-01],\n",
              "        [-3.5538086e-01,  5.1155525e-01]], dtype=float32),\n",
              " array([ 0.10189983, -0.10189985], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I53Pu2Hg2wqv",
        "outputId": "70d5095d-ed09-4500-f71b-ad6301a1e277"
      },
      "source": [
        "new_model.optimizer # To check the optimizer"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.adam.Adam at 0x7f6862c5f4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeNcnKMa3Bsh"
      },
      "source": [
        "#### 2. `model.to_json()`\n",
        "\n",
        "If you only need to save the architecture of a model, and not its weight or its training configuration, you can use the following function to save the architecture only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikTy49KF29JO"
      },
      "source": [
        "json_string = model.to_json()  # Saves as json\n",
        "# save as YAML\n",
        "# yaml_string = model.to_yaml()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "fsBW4ryt3W_f",
        "outputId": "fb2a5e6e-6a40-4d29-c4de-a6ce58ad892c"
      },
      "source": [
        "json_string"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.5.0\", \"backend\": \"tensorflow\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh4EBGY03eQP",
        "outputId": "9af140c3-1974-4e4f-e818-3593f4bb7bc8"
      },
      "source": [
        "# Model reconstruction from JSON\n",
        "from tensorflow.keras.models import model_from_json\n",
        "model_architecture = model_from_json(json_string)\n",
        "\n",
        "# To do the same with YAML\n",
        "# Replace json with yaml\n",
        "\n",
        "model_architecture.summary()\n",
        "\n",
        "# we have only the architecture\n",
        "# we would have to retrain the model to update the weights"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpyOcLkL4DOB"
      },
      "source": [
        "#### 3. `model.save_weights()`\n",
        "\n",
        "If you only need to save the weights of a model, you can use the following function to save the weights only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIBQST8L39Qp"
      },
      "source": [
        "if os.path.isfile(\"YOUR_PATH/weights.h5\") is False:\n",
        "  model.save_weights('YOUR_PATH/weights.h5')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COU6lJpm4pJu"
      },
      "source": [
        "# if we saved the weights and if we didn't save the model\n",
        "# Then we have create the exact architecture once again\n",
        "model2 = Sequential([\n",
        "            Dense(units=16, input_shape=(1,), activation='relu'),\n",
        "            Dense(units=32, activation='relu'),\n",
        "            Dense(units=2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Loading the wieghts backs\n",
        "model2.load_weights(\"YOUR_PATH/weights.h5\")\n",
        "# model2.get_weights()  "
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}